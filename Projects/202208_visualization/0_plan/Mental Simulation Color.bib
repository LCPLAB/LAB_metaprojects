@incollection{barsalouLanguageSimulationConceptual2008,
  title = {Language and Simulation in Conceptual Processing},
  author = {Barsalou, Lawrence W. and Santos, Ava and Simmons, W. Kyle and Wilson, Christine D.},
  editor = {{de Vega}, Manuel and Glenberg, Arthur and Graesser, Arthur},
  year = {2008},
  pages = {245--284},
  publisher = {{Oxford University Press}},
  address = {{Oxford}},
  abstract = {This chapter explains that multiple systems represent knowledge. It focuses on two resources of knowledge, believed to have strong empirical support \textemdash{} linguistic forms in the brain's language systems, and situated simulations in the brain's modal systems. Although this chapter focuses on two sources of knowledge, it does not exclude the possibility that other types are important as well. It argues that statistical representations play central roles throughout the brain, and that they underlie linguistic forms and situated simulations. It examines linguistic and modal approaches to the representation of knowledge. It proposes the language and situated simulation (LASS) theory as a preliminary framework for integrating these approaches. It then explores the evidence for the LASS theory, including evidence for dual code theory, Glaser's (1922) revision of dual code theory or the lexical hypothesis, evidence from the laboratories.},
  isbn = {978-0-19-921727-4},
  langid = {british},
  file = {D\:\\core\\reading\\Booknote\\barsalou.lang-simul.ch08.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Theory\\barsalouLanguageSimulationConceptual2008-zotero.md}
}

@article{barsalouPerceptualSymbolSystems1999,
  title = {Perceptual Symbol Systems},
  author = {Barsalou, Lawrence W.},
  year = {1999},
  journal = {Behavioral and Brain Sciences},
  volume = {22},
  pages = {577--660},
  doi = {10.1017/S0140525X99002149},
  file = {D\:\\core\\reading\\bbs\\Barsalou_BBS_1999_perceptual_symbol_systems.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Theory\\barsalouPerceptualSymbolSystems1999-zotero.md}
}

@book{bergenLouderWordsNew2012,
  title = {Louder {{Than Words}}: {{The New Science}} of {{How}} the {{Mind Makes Meaning}}},
  author = {Bergen, Benjamin K.},
  year = {2012},
  publisher = {{Basic Books}},
  abstract = {Whether it's brusque, convincing, fraught with emotion, or dripping with innuendo, language is fundamentally a tool for conveying meaning\textemdash a uniquely human magic trick in which you vibrate your vocal cords to make your innermost thoughts pop up in someone else's mind. You can use it to talk about all sorts of things\textemdash from your new labradoodle puppy to the expansive gardens at Versailles, from Roger Federer's backhand to things that don't exist at all, like flying pigs. And when you talk, your listener fills in lots of details you didn't mention\textemdash the curliness of the dog's fur or the vast statuary on the grounds of the French palace. What's the trick behind this magic? How does meaning work? In Louder than Words, cognitive scientist Benjamin Bergen draws together a decade's worth of research in psychology, linguistics, and neuroscience to offer a new theory of how our minds make meaning. When we hear words and sentences, Bergen contends, we engage the parts of our brain that we use for perception and action, repurposing these evolutionarily older networks to create simulations in our minds. These embodied simulations, as they're called, are what makes it possible for us to become better baseball players by merely visualizing a well-executed swing; what allows us to remember which cupboard the diapers are in without looking, and what makes it so hard to talk on a cell phone while we're driving on the highway. Meaning is more than just knowing definitions of words, as others have previously argued. In understanding language, our brains engage in a creative process of constructing rich mental worlds in which we see, hear, feel, and act. Through whimsical examples and ingenious experiments, Bergen leads us on a virtual tour of the new science of embodied cognition. A brilliant account of our human capacity to understand language, Louder than Words will profoundly change how you read, speak, and listen.},
  isbn = {0-465-02829-2},
  file = {D\:\\core\\reading\\Booknote\\louder than words.epub;D\:\\core\\reading\\Booknote\\louder than words.epub}
}

@article{bocanegraLanguageConcatenatesPerceptual2022,
  title = {Language Concatenates Perceptual Features into Representations during Comprehension},
  author = {Bocanegra, Bruno R. and Poletiek, Fenna H. and Zwaan, Rolf A.},
  year = {2022},
  month = dec,
  journal = {Journal of Memory and Language},
  volume = {127},
  pages = {104355},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2022.104355},
  abstract = {Although many studies have investigated the activation of perceptual representations during language comprehension, to our knowledge only one previous study has directly tested how perceptual features are combined into representations during comprehension. In their classic study, Potter and Faulconer [(1979). Understanding noun phrases. Journal of Verbal Learning and Verbal Behavior, 18, 509\textendash 521.] investigated the perceptual representation of adjective-noun combinations. However, their non-orthogonal design did not allow the differentiation between conjunctive vs. disjunctive representations. Using randomized orthogonal designs, we observe evidence for disjunctive perceptual representations when participants represent feature combinations simultaneously (in several experiments; N~=~469), and we observe evidence for conjunctive perceptual representations when participants represent feature combinations sequentially (In several experiments; N~=~628). Our findings show that the generation of conjunctive representations during comprehension depends on the concatenation of linguistic cues, and thus suggest the construction of elaborate perceptual representations may critically depend on language.},
  langid = {english},
  keywords = {Comprehension,Conjunction,Language,Perception,Simulation},
  file = {D\:\\core\\reading\\jml\\1-s2.0-S0749596X22000420-main.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\bocanegraLanguageConcatenatesPerceptual2022 - Annotations (7272022, 12335 PM).md;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods & Evidence\\bocanegraLanguageConcatenatesPerceptual2022-zotero.md}
}

@article{chenDoesObjectSize2020,
  title = {Does Object Size Matter with Regard to the Mental Simulation of Object Orientation?},
  author = {Chen, Sau-Chin and {de Koning}, Bjorn B. and Zwaan, Rolf A.},
  year = {2020},
  month = jan,
  journal = {Experimental Psychology},
  volume = {67},
  number = {1},
  pages = {56--72},
  issn = {1618-3169, 2190-5142},
  doi = {10.1027/1618-3169/a000468},
  abstract = {Abstract. Language comprehenders have been arguing to mentally represent the implied orientation of objects. However, compared to the effects of shape, size, and color, the effect of orientation is rather small. We examined a potential explanation for the relatively low magnitude of the orientation effect: Object size moderates the orientation effect. Theoretical considerations led us to predict a smaller orientation effect for small objects than for large objects in a sentence\textendash picture verification task. We furthermore investigated whether this pattern generalizes across languages (Chinese, Dutch, and English) and tasks (picture-naming task). The results of the verification task show an orientation effect overall, which is not moderated by object size (contrary to our hypothesis) and language (consistent with our hypothesis). Meanwhile, the preregistered picture\textendash picture verification task showed the predicted interaction between object size and orientation effect. We conducted exploratory analyses to address additional questions.},
  langid = {english},
  file = {D\:\\core\\reading\\CSC_Works\\Exppsy2020.pdf;D\:\\core\\reading\\CSC_Works\\MS-1651_preprint_final.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods & Evidence\\chenDoesObjectSize2020-zotero.md}
}

@inbook{connellColourStabilityEmbodied2005,
  title = {Colour and Stability in Embodied Representations},
  booktitle = {Proceedings of the Twenty-Seventh Annual Conference of the Cognitive Science Society.},
  author = {Connell, Louise},
  year = {2005},
  pages = {482--487},
  address = {{Mahwah, NJ: Lawrence Erlbaum}},
  collaborator = {Bara, B and Barsalou, Lawrence W. and Bucciarelli, M},
  file = {D\:\\core\\Version_Controls\\zotero_data\\storage\\D5F89FRF\\Connell-2005-CogSci.pdf}
}

@article{connellRepresentingObjectColour2007,
  title = {Representing Object Colour in Language Comprehension},
  author = {Connell, Louise},
  year = {2007},
  month = mar,
  journal = {Cognition},
  volume = {102},
  pages = {476--485},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2006.02.009},
  abstract = {Embodied theories of cognition hold that mentally representing something red engages the neural subsystems that respond to environmental perception of that colour. This paper examines whether implicit perceptual information on object colour is represented during sentence comprehension even though doing so does not necessarily facilitate task performance. After reading a sentence that implied a particular colour for a given object, participants were presented with a picture of the object that either matched or mismatched the implied colour. When asked if the pictured object was mentioned in the preceding sentence, people's responses were faster when the colours mismatched than when they matched, suggesting that object colour is represented differently to other object properties such as shape and orientation. A distinction between stable and unstable embodied representations is proposed to allow embodied theories to account for these findings.},
  keywords = {Colour,embodied cognition,Language comprehension,mental representation,Perception,Stability},
  file = {D\:\\core\\reading\\cognition\\1-s2.0-S0010027706000606-main.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods & Evidence\\connellRepresentingObjectColour2007-zotero.md}
}

@book{fodorLOTLanguageThought2008,
  title = {{{LOT}} 2: {{The}} Language of Thought Revisited},
  author = {Fodor, Jerry},
  year = {2008},
  publisher = {{Oxford University Press}},
  address = {{Oxford}},
  isbn = {0-19-954877-3},
  file = {D\:\\core\\reading\\Booknote\\LOT2.pdf;D\:\\core\\reading\\Booknote\\LOT2.pdf}
}

@article{hoebenmannaertColorContinuouslyActivated2021,
  title = {Is Color Continuously Activated in Mental Simulations across a Broader Discourse Context?},
  author = {Hoeben Mannaert, Lara N. and Dijkstra, Katinka and Zwaan, Rolf A.},
  year = {2021},
  month = jan,
  journal = {Memory \& Cognition},
  volume = {49},
  number = {1},
  pages = {127--147},
  issn = {1532-5946},
  doi = {10.3758/s13421-020-01078-6},
  abstract = {Previous studies have provided contradictory information regarding the activation of perceptual information in a changing discourse context. The current study examines the continued activation of color in mental simulations across one (Experiment 1), two (Experiment 2), and five sentences (Experiment 3), using a sentence-picture verification paradigm. In Experiment 1, the sentence either contained a reference to a color (e.g., a red bicycle) or no reference to a color (e.g., bicycle). In Experiments 2 and 3, either the first or the final sentence contained a reference to a color. Participants responded to pictures either matching the color mentioned in the sentence, or shown in grayscale. The results illustrated that color was activated in mental simulations when the final sentence contained a reference to color. When the target object (e.g., bicycle) was mentioned in all sentences (i.e., in Experiment 2), color remained activated in the mental simulation, even when only the first sentence made a reference to a color. When the focus of the story was shifted elsewhere and the target object was not present across all sentences (i.e., in Experiment 3), color was no longer activated in the mental simulation. These findings suggest that color remains active in mental simulations so long as the target object is present in every sentence. As soon as the focus of the story shifts to another event, this perceptual information is deactivated in the mental simulation. As such, there is no continued activation of color across a broader discourse context.},
  langid = {english},
  file = {D\:\\core\\reading\\m&c\\HoebenMannaert2021_Article_IsColorContinuouslyActivatedIn.pdf}
}

@article{hoebenmannaertColorIntegralPart2017a,
  title = {Is Color an Integral Part of a Rich Mental Simulation?},
  author = {Hoeben Mannaert, Lara N. and Dijkstra, Katinka and Zwaan, Rolf A.},
  year = {2017},
  month = aug,
  journal = {Memory \& Cognition},
  volume = {45},
  number = {6},
  pages = {974--982},
  issn = {1532-5946},
  doi = {10.3758/s13421-017-0708-1},
  abstract = {Research suggests that language comprehenders simulate visual features such as shape during language comprehension. In sentence-picture verification tasks, whenever pictures match the shape or orientation implied by the previous sentence, responses are faster than when the pictures mismatch implied visual aspects. However, mixed results have been demonstrated when the sentence-picture paradigm was applied to color (Connell, Cognition, 102(3), 476\textendash 485, 2007; Zwaan \& Pecher, PLOS ONE, 7(12), e51382, 2012). One of the aims of the current investigation was to resolve this issue. This was accomplished by conceptually replicating the original study on color, using the same paradigm but a different stimulus set. The second goal of this study was to assess how much perceptual information is included in a mental simulation. We examined this by reducing color saturation, a manipulation that does not sacrifice object identifiability. If reduction of one aspect of color does not alter the match effect, it would suggest that not all perceptual information is relevant for a mental simulation. Our results did not support this: We found a match advantage when objects were shown at normal levels of saturation, but this match advantage disappeared when saturation was reduced, yet still aided in object recognition compared to when color was entirely removed. Taken together, these results clearly show a strong match effect for color, and the perceptual richness of mental simulations during language comprehension.},
  langid = {english},
  file = {D\:\\core\\reading\\m&c\\s13421-017-0708-1.pdf}
}

@article{koning_mental_2017,
  title = {Mental Simulation of Four Visual Object Properties: Similarities and Differences as Assessed by the Sentence-Picture Verification Task},
  shorttitle = {Mental Simulation of Four Visual Object Properties},
  author = {De Koning, Bj{\"o}rn B. and Wassenburg, Stephanie I. and Bos, Lisanne T. and {Van der Schoot}, Menno},
  year = {2017},
  month = may,
  journal = {Journal of Cognitive Psychology},
  volume = {29},
  number = {4},
  pages = {420--432},
  issn = {2044-5911},
  doi = {10.1080/20445911.2017.1281283},
  abstract = {In the sentence\textendash picture verification (SPV) task, people read sentences implying the shape/size/colour/orientation of objects. They then verify whether pictured objects, which either match or mismatch the implied visual information mentioned in the sentence. Faster verification times on matching trials (match advantage) are considered supportive to the notion that readers perform mental simulations during sentence comprehension. This study advances this work by applying a within-subjects design to the SPV-task, enabling us to directly address the strength of and correlation between the match advantages for the properties shape, size, colour, and orientation. Results showed varying match advantages with colour showing the strongest effect, and no match advantage for orientation. Shape, size, and colour were significantly correlated, whereas there were no significant correlations with orientation. These findings suggest that interpretations of match advantages could benefit from a re-evaluation of mental simulation accountsby distinguishing between intrinsic (shape, size, and colour) and extrinsic (orientation) object properties.},
  keywords = {embodied cognition,Mental simulation,Reading comprehension,sentencepicture verification task},
  file = {D\:\\core\\reading\\unsort\\Manuscript_De Koning, Wassenburg, Bos & van der Schoot (submitted).pdf;D\:\\core\\reading\\unsort\\Manuscript_De Koning, Wassenburg, Bos & van der Schoot (submitted).pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods & Evidence\\koning_mental_2017-zotero.md;D\:\\core\\Version_Controls\\zotero_data\\storage\\4WX6EGU9\\20445911.2017.html;D\:\\core\\Version_Controls\\zotero_data\\storage\\IDUIM5J7\\20445911.2017.html}
}

@article{ostarekAreVisualProcesses2019,
  title = {Are Visual Processes Causally Involved in ``Perceptual Simulation'' Effects in the Sentence-Picture Verification Task?},
  author = {Ostarek, Markus and Joosen, Dennis and Ishag, Adil and {de Nijs}, Monique and Huettig, Falk},
  year = {2019},
  month = jan,
  journal = {Cognition},
  volume = {182},
  pages = {84--94},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2018.08.017},
  abstract = {Many studies have shown that sentences implying an object to have a certain shape produce a robust reaction time advantage for shape-matching pictures in the sentence-picture verification task. Typically, this finding has been interpreted as evidence for perceptual simulation, i.e., that access to implicit shape information involves the activation of modality-specific visual processes. It follows from this proposal that disrupting visual processing during sentence comprehension should interfere with perceptual simulation and obliterate the match effect. Here we directly test this hypothesis. Participants listened to sentences while seeing either visual noise that was previously shown to strongly interfere with basic visual processing or a blank screen. Experiments 1 and 2 replicated the match effect but crucially visual noise did not modulate it. When an interference technique was used that targeted high-level semantic processing (Experiment 3) however the match effect vanished. Visual noise specifically targeting high-level visual processes (Experiment 4) only had a minimal effect on the match effect. We conclude that the shape match effect in the sentence-picture verification paradigm is unlikely to rely on perceptual simulation.},
  langid = {english},
  file = {D\:\\core\\reading\\cognition\\1-s2.0-S0010027718302233-main.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\001_MentalSimulation\\Mental Simulation\\03_Methods & Evidence\\ostarekAreVisualProcesses2018-12-31 - Ostarek et al. (2019) Annotations.md;D\:\\core\\research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods & Evidence\\ostarekAreVisualProcesses2019-zotero.md}
}

@article{ostarekSixChallengesEmbodiment2019a,
  title = {Six {{Challenges}} for {{Embodiment Research}}},
  author = {Ostarek, Markus and Huettig, Falk},
  year = {2019},
  month = dec,
  journal = {Current Directions in Psychological Science},
  volume = {28},
  number = {6},
  pages = {593--599},
  issn = {0963-7214},
  doi = {10.1177/0963721419866441},
  abstract = {Twenty years after Barsalou's seminal perceptual-symbols article, embodied cognition, the notion that cognition involves simulations of sensory, motor, or affective states, has moved from an outlandish proposal to a mainstream position adopted by many researchers in the psychological and cognitive sciences (and neurosciences). Though it has generated productive work in the cognitive sciences as a whole, it has had a particularly strong impact on research into language comprehension. The view of a mental lexicon based on symbolic word representations, which are arbitrarily linked to sensory aspects of their referents, was generally accepted since the cognitive revolution in the 1950s. This has radically changed. Given the current status of embodiment as a main theory of cognition, it is somewhat surprising that a close look at the literature reveals that the debate about the nature of the processes involved in language comprehension is far from settled, and key questions remain unanswered. We present several suggestions for a productive way forward.},
  langid = {english},
  keywords = {cognition,conceptual processing,embodiment,language},
  file = {D\:\\core\\reading\\unsort\\0963721419866441.pdf;D\:\\core\\research\\projects\\Mnetal_Simulation\\001_MentalSimulation\\Mental Simulation\\01_Issues\\ostarekSixChallengesEmbodiment2019 - Annotations.md;D\:\\core\\research\\projects\\Mnetal_Simulation\\001_MentalSimulation\\Mental Simulation\\01_Issues\\ostarekSixChallengesEmbodiment2019 - Annotations.md}
}

@article{stanfield_effect_2001,
  title = {The Effect of Implied Orientation Derived from Verbal Context on Picture Recognition},
  author = {Stanfield, Robert A. and Zwaan, Rolf A.},
  year = {2001},
  month = mar,
  journal = {Psychological Science},
  volume = {12},
  number = {2},
  pages = {153--156},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00326},
  abstract = {Perceptual symbol systems assume an analogue relationship between a symbol and its referent, whereas amodal symbol systems assume an arbitrary relationship between a symbol and its referent. According to perceptual symbol theories, the complete representation of an object, called a simulation, should reflect physical characteristics of the object. Amodal theories, in contrast, do not make this prediction. We tested the hypothesis, derived from perceptual symbol theories, that people mentally represent the orientation of an object implied by a verbal description. Orientation (vertical-horizontal) was manipulated by having participants read a sentence that implicitly suggested a particular orientation for an object. Then recognition latencies to pictures of the object in each of the two orientations were measured. Pictures matching the orientation of the object implied by the sentence were responded to faster than pictures that did not match the orientation. This finding is interpreted as offering support for theories positing perceptual symbol systems.},
  langid = {english},
  pmid = {11340925},
  keywords = {orientation},
  file = {D\:\\core\\reading\\psychological science\\Psychological Science-2001-Stanfield-153-6.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods\\stanfield_effect_2001.md}
}

@article{zwaanLanguageComprehendersMentally2002,
  title = {Language Comprehenders Mentally Represent the Shapes of Objects},
  author = {Zwaan, Rolf A. and Stanfield, Robert A. and Yaxley, Richard H.},
  year = {2002},
  month = mar,
  journal = {Psychological Science},
  volume = {13},
  pages = {168--171},
  doi = {10.1111/1467-9280.00430},
  abstract = {We examined the prediction that people activate perceptual symbols during language comprehension. Subjects read sentences describing an animal or object in a certain location. The shape of the object or animal changed as a function of its location (e.g., eagle in the sky, eagle in a nest). However, this change was only implied by the sentences. After reading a sentence, subjects were presented with a line drawing of the object in question. They judged whether the object had been mentioned in the sentence (Experiment 1) or simply named the object (Experiment 2). In both cases, responses were faster when the pictured object's shape matched the shape implied by the sentence than when there was a mismatch. These results support the hypothesis that perceptual symbols are routinely activated in language comprehension.},
  keywords = {shape},
  file = {D\:\\core\\reading\\psychological science\\Psychological Science-2002-Zwaan-168-71.pdf;D\:\\core\\reading\\psychological science\\Psychological Science-2002-Zwaan-168-71.pdf;D\:\\core\\Research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods\\zwaanLanguageComprehendersMentally2002.md}
}

@article{zwaanRevisitingMentalSimulation2012,
  title = {Revisiting Mental Simulation in Language Comprehension: Six Replication Attempts},
  author = {Zwaan, Rolf A. and Pecher, Diane},
  year = {2012},
  journal = {PLoS ONE},
  volume = {7},
  pages = {e51382},
  doi = {10.1371/journal.pone.0051382},
  abstract = {The notion of language comprehension as mental simulation has become popular in cognitive science. We revisit some of the original empirical evidence for this. Specifically, we attempted to replicate the findings from earlier studies that examined the mental simulation of object orientation, shape, and color, respectively, in sentence-picture verification. For each of these sets of findings, we conducted two web-based replication attempts using Amazon's Mechanical Turk. Our results are mixed. Participants responded faster to pictures that matched the orientation or shape implied by the sentence, replicating the original findings. The effect was larger and stronger for shape than orientation. Participants also responded faster to pictures that matched the color implied by the sentence, whereas the original studies obtained {$<$}italic{$>$}mis{$<$}/italic{$>$}match advantages. We argue that these results support mental simulation theory, show the importance of replication studies, and show the viability of web-based data collection.},
  keywords = {color,orientation,shape},
  file = {D\:\\core\\reading\\PLOS\\0051382.pdf;D\:\\core\\reading\\PLOS\\journal.pone.0051382.t001.png;D\:\\core\\research\\projects\\Mnetal_Simulation\\cards\\Mental Simulation\\Methods & Evidence\\zwaanRevisitingMentalSimulation2012-zotero.md}
}
